{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd14df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import dotenv\n",
    "from twon_lss.utility import LLM, Message, Chat\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c6e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = dotenv.dotenv_values(\"../\" * 3 + \".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341940a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2712943/2792471165.py:1: DtypeWarning:\n",
      "\n",
      "Columns (2,3,6,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/FolloweeIDs2_tweets_df_AugustPull.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8556e9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive regex including figures, organizations, and variants\n",
    "# Grouped logically for maintenance, compiled once for performance.\n",
    "covid_expanded_pattern = re.compile(\n",
    "    r'\\b('\n",
    "    # 1. Core Virus Identifiers\n",
    "    r'covid(-?19)?|corona(virus)?|sars-?cov-?2|n?cov(-?19|2019)?|'\n",
    "    \n",
    "    # 2. Key Variants\n",
    "    r'omicron|delta|alpha|beta|ba\\.\\d+|xbb|'\n",
    "    \n",
    "    # 3. Medical & Vaccine Manufacturers\n",
    "    r'pfizer|moderna|astrazeneca|biontech|j&j|johnson & johnson|'\n",
    "    r'novavax|sinovac|sputnik v|'\n",
    "    \n",
    "    # 4. Slang & Colloquial\n",
    "    r'the\\s?rona|miss\\s?rona|covidiot|vax(xed)?|antivax(xer)?|'\n",
    "    \n",
    "    # 5. High-Signal Context Specifics\n",
    "    r'quarantine|lockdown|pandemic|epidemic|'\n",
    "    r'social distanc(ing|e)|herd immunity|'\n",
    "    r'wuhan (lab|market)|'\n",
    "    r'super-?spreader|long covid'\n",
    "    r')\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def is_covid_relevant(tweet_text):\n",
    "    \"\"\"\n",
    "    Returns True if the tweet contains any major COVID-19 keywords, \n",
    "    key figures, or organizations associated with the pandemic.\n",
    "    \"\"\"\n",
    "    if not tweet_text:\n",
    "        return False\n",
    "    return bool(covid_expanded_pattern.search(tweet_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f555775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the profiler prompts\n",
    "with open(\"../data/profiler.bio.txt\", \"r\") as f:\n",
    "    BIO_PROFILER_PROMPT = f.read()\n",
    "\n",
    "with open(\"../data/profiler.cognition.txt\", \"r\") as f:\n",
    "    COGNITION_PROFILER_PROMPT = f.read()\n",
    "\n",
    "# Load the instructions\n",
    "with open(\"../data/agents.instructions.json\", \"r\") as f:\n",
    "    INSTRUCTIONS = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c69fe30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_posts_per_day(df):\n",
    "    num_days = (pd.to_datetime(df[\"created_at\"]).max() - pd.to_datetime(df[\"created_at\"]).min()).days\n",
    "    total_posts = len(df)\n",
    "    posts_per_day = total_posts / num_days if num_days > 0 else 0\n",
    "    return posts_per_day \n",
    "\n",
    "\n",
    "def df_to_history_string(df) -> str:\n",
    "    \"\"\"Parse the history from the json format to the Message format.\"\"\"\n",
    "    history_string = \"\"\n",
    "    for i, message in df.iterrows():\n",
    "        history_string += f\">Tweet written by you: {message['full_text']}\\n\"\n",
    "    return history_string\n",
    "\n",
    "\n",
    "def df_to_llm_history(df) -> list[Message]:\n",
    "    \"\"\"Parse the history from the json format to the Message format.\"\"\"\n",
    "    parsed_history = []\n",
    "\n",
    "    for i, message in df.iterrows():\n",
    "            parsed_history.append({\"role\": \"user\", \"content\": f\"{INSTRUCTIONS['actions']['post_prompt']}\"})\n",
    "            parsed_history.append({\"role\": \"assistant\", \"content\": f\"{message['full_text']}\"})\n",
    "\n",
    "    return parsed_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b58eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Profiler LLM\n",
    "AGENT_LLM = LLM(api_key=ENV[\"HF_TOKEN\"], model=\"Qwen/Qwen3-235B-A22B-Instruct-2507:cerebras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40382daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing agent personas\n",
    "with open(\"../data/agents.personas.json\", \"r\") as f:\n",
    "    PERSONA_PROFILES = json.load(f)\n",
    "\n",
    "with open(\"../data/agents.personas_covid.json\", \"r\") as f:\n",
    "    PERSONA_PROFILES_COVID = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51c781d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 14803/34696 [57:02<1:54:39,  2.89it/s] ERROR:root:Failed to query LLM: 'choices'\n",
      " 48%|████▊     | 16509/34696 [1:14:27<5:06:13,  1.01s/it] ERROR:root:Failed to query LLM: 'choices'\n",
      " 50%|████▉     | 17323/34696 [1:23:14<9:56:08,  2.06s/it]  ERROR:root:Failed to query LLM: 'choices'\n",
      " 54%|█████▎    | 18632/34696 [1:39:22<1:32:26,  2.90it/s]  ERROR:root:Failed to query LLM: 'choices'\n",
      " 58%|█████▊    | 20241/34696 [1:57:15<1:23:44,  2.88it/s] ERROR:root:Failed to query LLM: 'choices'\n",
      " 60%|█████▉    | 20809/34696 [2:05:05<2:46:07,  1.39it/s] ERROR:root:Failed to query LLM: 'choices'\n",
      " 60%|█████▉    | 20816/34696 [2:06:21<15:05:38,  3.91s/it]ERROR:root:Failed to query LLM: 'choices'\n",
      " 62%|██████▏   | 21354/34696 [2:12:55<4:57:50,  1.34s/it] ERROR:root:Failed to query LLM: 'choices'\n",
      " 62%|██████▏   | 21431/34696 [2:14:35<1:17:13,  2.86it/s] ERROR:root:Failed to query LLM: 'choices'\n",
      " 62%|██████▏   | 21633/34696 [2:17:22<1:15:11,  2.90it/s] ERROR:root:Failed to query LLM: 'choices'\n",
      " 62%|██████▏   | 21634/34696 [2:18:30<74:57:34, 20.66s/it]ERROR:root:Failed to query LLM: 'choices'\n",
      " 63%|██████▎   | 21974/34696 [2:22:24<6:27:59,  1.83s/it]  ERROR:root:Failed to query LLM: 'choices'\n",
      " 66%|██████▌   | 22757/34696 [2:32:41<2:36:51,  1.27it/s] ERROR:root:Failed to query LLM: 'choices'\n",
      " 66%|██████▌   | 22771/34696 [2:33:59<3:59:18,  1.20s/it] ERROR:root:Failed to query LLM: 'choices'\n",
      " 66%|██████▌   | 22787/34696 [2:35:47<7:12:53,  2.18s/it] ERROR:root:Failed to query LLM: 'choices'\n",
      " 66%|██████▌   | 22879/34696 [2:39:00<3:30:27,  1.07s/it] ERROR:root:Failed to query LLM: 'choices'\n",
      "ERROR:root:Failed to query LLM: 'choices'\n",
      " 66%|██████▌   | 22883/34696 [2:41:14<46:14:15, 14.09s/it] ERROR:root:Failed to query LLM: 'choices'\n",
      "ERROR:root:Failed to query LLM: 'choices'\n",
      " 66%|██████▌   | 22905/34696 [2:43:56<11:40:36,  3.57s/it] ERROR:root:Failed to query LLM: 'choices'\n",
      " 67%|██████▋   | 23159/34696 [2:48:19<1:06:54,  2.87it/s] ERROR:root:Failed to query LLM: 'choices'\n",
      " 67%|██████▋   | 23227/34696 [2:50:05<1:06:05,  2.89it/s] ERROR:root:Failed to query LLM: 'choices'\n",
      " 67%|██████▋   | 23263/34696 [2:51:29<1:08:50,  2.77it/s] ERROR:root:Failed to query LLM: 'choices'\n",
      " 67%|██████▋   | 23286/34696 [2:53:21<3:46:26,  1.19s/it] ERROR:root:Failed to query LLM: 'choices'\n",
      " 67%|██████▋   | 23295/34696 [2:54:40<7:40:07,  2.42s/it] ERROR:root:Failed to query LLM: 'choices'\n",
      "ERROR:root:Failed to query LLM: 'choices'\n",
      "ERROR:root:Failed to query LLM: 'choices'\n",
      " 67%|██████▋   | 23298/34696 [2:57:54<93:08:24, 29.42s/it] ERROR:root:Failed to query LLM: 'choices'\n",
      " 67%|██████▋   | 23338/34696 [2:59:42<1:58:57,  1.59it/s]  ERROR:root:Failed to query LLM: 'choices'\n",
      " 67%|██████▋   | 23341/34696 [3:00:48<31:27:09,  9.97s/it]ERROR:root:Failed to query LLM: 'choices'\n",
      " 70%|███████   | 24356/34696 [3:15:01<1:00:17,  2.86it/s] ERROR:root:Failed to query LLM: 'choices'\n",
      " 71%|███████▏  | 24801/34696 [3:20:13<1:15:34,  2.18it/s] ERROR:root:Failed to query LLM: 'choices'\n",
      " 73%|███████▎  | 25490/34696 [3:28:39<57:35,  2.66it/s]   ERROR:root:Failed to query LLM: 'choices'\n",
      " 74%|███████▍  | 25685/34696 [3:31:43<53:04,  2.83it/s]   ERROR:root:Failed to query LLM: 'choices'\n",
      " 74%|███████▍  | 25770/34696 [3:33:43<3:12:29,  1.29s/it] ERROR:root:Failed to query LLM: 'choices'\n",
      " 75%|███████▍  | 25973/34696 [3:37:00<1:05:11,  2.23it/s] ERROR:root:Failed to query LLM: 'choices'\n",
      " 78%|███████▊  | 26957/34696 [3:49:42<46:40,  2.76it/s]   ERROR:root:Failed to query LLM: 'choices'\n",
      " 79%|███████▉  | 27393/34696 [3:55:13<2:01:19,  1.00it/s] ERROR:root:Failed to query LLM: 'choices'\n",
      " 79%|███████▉  | 27480/34696 [3:57:41<1:02:24,  1.93it/s] \n"
     ]
    }
   ],
   "source": [
    "for screen_name in tqdm(df[\"screen_name\"].unique().tolist()):\n",
    "\n",
    "    if len([persona for persona in PERSONA_PROFILES_COVID if persona[\"covid_flag\"] == True]) >= 2000:\n",
    "        break\n",
    "\n",
    "    if any(persona.get(\"screen_name\") == screen_name for persona in PERSONA_PROFILES_COVID):\n",
    "        continue\n",
    "\n",
    "    if any(persona.get(\"screen_name\") == screen_name for persona in PERSONA_PROFILES):\n",
    "        # get history of existing persona\n",
    "        for persona in PERSONA_PROFILES:\n",
    "            if persona.get(\"screen_name\") == screen_name:\n",
    "                history = persona.get(\"history\", [])\n",
    "                profile = persona\n",
    "                break\n",
    "        \n",
    "        covid_flag = False\n",
    "        if is_covid_relevant(\"\".join(message[\"content\"].lower() for message in history)):\n",
    "            covid_flag = True\n",
    "\n",
    "        if not covid_flag:\n",
    "            # update user prompt in history \n",
    "            for message in history:\n",
    "                if message[\"role\"] == \"user\":\n",
    "                    message[\"content\"] = INSTRUCTIONS[\"actions\"][\"post_prompt\"]\n",
    "                    \n",
    "            profile[\"covid_flag\"] = False\n",
    "            profile[\"covid_tweets\"] = []\n",
    "            PERSONA_PROFILES_COVID.append(profile)\n",
    "            continue\n",
    "\n",
    "    persona_dict = {\"screen_name\": screen_name}\n",
    "\n",
    "    # Filter to original tweets only\n",
    "    filtered_df = df[df[\"screen_name\"] == screen_name].drop_duplicates(subset=[\"full_text\"])\n",
    "\n",
    "    filtered_df[\"reply_to_user\"] = filtered_df[\"reply_to_user\"].astype(str)\n",
    "    filtered_df = filtered_df[filtered_df[\"reply_to_user\"] == \"nan\"]\n",
    "\n",
    "    filtered_df[\"retweeted_user_ID\"] = filtered_df[\"retweeted_user_ID\"].astype(str)\n",
    "    filtered_df = filtered_df[filtered_df[\"retweeted_user_ID\"] == \"nan\"]\n",
    "\n",
    "    filtered_df = filtered_df.sort_values(by=\"created_at\").reset_index(drop=True)\n",
    "\n",
    "    # Calculate posts per day\n",
    "    posts_per_day = determine_posts_per_day(filtered_df)\n",
    "\n",
    "    # Drop any posts that contains an URL\n",
    "    filtered_df = filtered_df[~filtered_df[\"full_text\"].str.contains(\"http\")].reset_index(drop=True)\n",
    "    if len(filtered_df) < 5:\n",
    "        continue\n",
    "\n",
    "    # Identify COVID-related tweets and drop them from the dataframe\n",
    "    covid_tweets = []\n",
    "    for i, row in filtered_df.iterrows():\n",
    "        tweet_text = row[\"full_text\"].lower()\n",
    "        if is_covid_relevant(tweet_text):\n",
    "            covid_tweets.append(row[\"full_text\"])\n",
    "\n",
    "    # !!! Currently only process users with COVID tweets - remove this condition to profile all users\n",
    "    if not covid_tweets:\n",
    "        continue\n",
    "\n",
    "    filtered_df = filtered_df[~filtered_df[\"full_text\"].apply(lambda x: is_covid_relevant(x.lower()))].reset_index(drop=True)\n",
    "\n",
    "    bio = AGENT_LLM.generate(\n",
    "        Chat([\n",
    "            Message(role=\"user\", content=BIO_PROFILER_PROMPT.format(history=df_to_history_string(filtered_df))),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    cognition = AGENT_LLM.generate(\n",
    "        Chat([\n",
    "            Message(role=\"user\", content=COGNITION_PROFILER_PROMPT.format(history=df_to_history_string(filtered_df), bio=bio))\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    persona_dict[\"bio\"] = bio\n",
    "    persona_dict[\"cognition\"] = cognition\n",
    "    persona_dict[\"history\"] = df_to_llm_history(filtered_df)\n",
    "    persona_dict[\"posts_per_day\"] = posts_per_day\n",
    "    persona_dict[\"covid_flag\"] = True if covid_tweets else False\n",
    "    persona_dict[\"covid_tweets\"] = covid_tweets\n",
    "\n",
    "    PERSONA_PROFILES_COVID.append(persona_dict)\n",
    "\n",
    "    # Save as JSON\n",
    "    with open(\"../data/agents.personas_covid.json\", \"w\") as f:\n",
    "        json.dump(PERSONA_PROFILES_COVID, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twon-lss (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
